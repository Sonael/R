xbar <- rep(NA,n)
{
MinhaAmostra <- sample(flu$age,size = tammedia)
xbar[i] <- mean(MinhaAmostra)
}
for(i in 1:n)
{
MinhaAmostra <- sample(flu$age,size = tammedia)
xbar[i] <- mean(MinhaAmostra)
}
hist(xbar)
hist(xbar)
densityFlu <- density(xbar)
lines(densityFlu)
hist(Temperature,col="grey",
probability = T)
densityTemp <- density(Temperature)
lines(densityTemp)
hist(xbar,col="grey",
probability = T)
densityFlu <- density(xbar)
lines(densityFlu)
tammedia <- 500
{
MinhaAmostra <- sample(flu$age,size = tammedia)
xbar[i] <- mean(MinhaAmostra)
}
hist(xbar,col="grey",
probability = T, main = 'Histogram of Flu')
densityFlu <- density(xbar)
lines(densityFlu)
flu <- read.csv2('flu.csv')
n <- 100
tammedia <- 500
xbar <- rep(NA,n)
for(i in 1:n)
{
MinhaAmostra <- sample(flu$age,size = tammedia)
xbar[i] <- mean(MinhaAmostra)
}
hist(xbar,col="grey",
probability = T, main = 'Histogram of Flu')
densityFlu <- density(xbar)
lines(densityFlu)
hist(xbar,col="grey",
probability = T, main = 'Histogram of Flu',
xlab = 'Age')
densityFlu <- density(xbar)
lines(densityFlu)
flu <- read.csv2('flu.csv')
n <- 100
tammedia <- 30
xbar <- rep(NA,n)
for(i in 1:n)
{
MinhaAmostra <- sample(flu$age,size = tammedia)
xbar[i] <- mean(MinhaAmostra)
}
hist(xbar,col="grey",
probability = T, main = 'Histogram of Flu',
xlab = 'Age')
densityFlu <- density(xbar)
lines(densityFlu)
flu <- read.csv2('flu.csv')
n <- 100
tammedia <- 30
xbar <- rep(NA,n)
for(i in 1:n)
{
MinhaAmostra <- sample(flu$age,size = tammedia)
xbar[i] <- mean(MinhaAmostra)
}
hist(xbar,col="grey",
probability = T, main = 'Histogram of Flu',
xlab = 'Age')
densityFlu <- density(xbar)
lines(densityFlu)
flu <- read.csv2('flu.csv')
n <- 100
tammedia <- 30
xbar <- rep(NA,n)
for(i in 1:n)
{
MinhaAmostra <- sample(flu$age,size = tammedia)
xbar[i] <- mean(MinhaAmostra)
}
hist(xbar,col="grey",
probability = T, main = 'Histogram of Flu',
xlab = 'Age')
densityFlu <- density(xbar)
lines(densityFlu)
flu <- read.csv2('flu.csv')
n <- 100
tammedia <- 30
xbar <- rep(NA,n)
for(i in 1:n)
{
MinhaAmostra <- sample(flu$age,size = tammedia)
xbar[i] <- mean(MinhaAmostra)
}
hist(xbar,col="grey",
probability = T, main = 'Histogram of Flu',
xlab = 'Age')
densityFlu <- density(xbar)
lines(densityFlu)
flu <- read.csv2('flu.csv')
n <- 100
tammedia <- 30
xbar <- rep(NA,n)
for(i in 1:n)
{
MinhaAmostra <- sample(flu$age,size = tammedia)
xbar[i] <- mean(MinhaAmostra)
}
hist(xbar,col="grey",
probability = T, main = 'Histogram of Flu',
xlab = 'Age')
densityFlu <- density(xbar)
lines(densityFlu)
flu <- read.csv2('flu.csv')
n <- 100
tammedia <- 30
xbar <- rep(NA,n)
for(i in 1:n)
{
MinhaAmostra <- sample(flu$age,size = tammedia)
xbar[i] <- mean(MinhaAmostra)
}
hist(xbar,col="grey",
probability = T, main = 'Histogram of Flu',
xlab = 'Age')
densityFlu <- density(xbar)
lines(densityFlu)
hist(flu,col="grey",
probability = T, main = 'Histogram of Flu',
xlab = 'Age')
densityFlu <- density(xbar)
lines(densityFlu)
hist(flu$age,col="grey",
probability = T, main = 'Histogram of Flu',
xlab = 'Age')
densityFlu <- density(xbar)
lines(densityFlu)
hist(flu$age,col="grey",
probability = T, main = 'Histogram of Flu',
xlab = 'Age')
densityFlu <- density(xbar)
lines(densityFlu)
sd <- 0.5
N <- 300
erro <- 0.1
nc <- (1-0.99)/2
n <- (qnorm(nc,lower.tail = F)^2*sd^2*N)/((erro^2*(N-1)))+(qnorm(nc,lower.tail = F)^2*sd^2)
n
round(n,2)
library(MASS)
attach(anorexia)
View(anorexia)
verificaHO <- function(pvalue,ns=0.05)
{
if(pvalue > ns)
{
print("Aceita hipotese nula")
}
else
{
print("Rejeita a hipotese nula")
}
}
verificaNormalidade <- function(x,ns=0.05)
{
if(length(x) <= 50)
{
x <- shapiro.test(x)
}
else
{
require(nortest)
x <- ad.test(x)
}
if(x$p.value>ns)
{
print("os dados seguem uma distribuição normal")
}
else
{
print("Os dados não seguem uma distribuição normal")
}
}
verificaVariancias <- function(x,y,ns=0.05)
{
x <- var.test(x,y)
if(x$p.value > ns)
{
print("As variancias são homogeneas")
}
else
{
print("As variancias não são homogeneas")
}
}
antes <- anorexia$Prewt
depois <- anorexia$Postwt
peso <- t.test(antes,depois,paired = T,
var.equal = T)
View(peso)
verificaHO(peso$p.value)
verificaHO(peso$p.value)
verificaHO(temperatura$p.value)
verificaNormalidade(antes)
verificaNormalidade(depois)
verificaVariancias(antes, depois)
install.packages("nortest")
install.packages("nortest")
library(nortest)
verificaHO(peso$p.value)
verificaHO(temperatura$p.value)
verificaNormalidade(antes)
verificaNormalidade(depois)
verificaVariancias(antes, depois)
verificaHO(peso$p.value)
verificaHO(temperatura$p.value)
verificaNormalidade(antes)
verificaNormalidade(depois)
verificaVariancias(antes, depois)
verificaHO(peso$p.value)
verificaNormalidade(antes)
verificaNormalidade(depois)
verificaVariancias(antes, depois)
20_anos <- c(27, 26, 21, 24,15,18, 17,12,13)
vinte_anos <- c(27, 26, 21, 24,15,18, 17,12,13)
sessenta_anos <- c(26, 29, 29, 29, 27,16, 20, 27)
###############################################################################
nc = 0.05
verificaVariancias(vinte_anos, sessenta_anos)
verificaNormalidade(sessenta_anos)
verificaNormalidade(vinte_anos)
verificaHO(peso$p.value)
verificaHO(voca$p.value)
voca <- t.test(vinte_anos,sessenta_anos,alternative = "two.sided", conf.level = nc, var.equal = T)
verificaHO(voca$p.value)
voca$p.value
voca <- t.test(vinte_anos,sessenta_anos,alternative = "two.sided", conf.level = nc, var.equal = T)
verificaHO(voca$p.value)
verificaNormalidade(vinte_anos)
verificaNormalidade(sessenta_anos)
verificaVariancias(vinte_anos, sessenta_anos)
x <- c(8.8,8.4,7.9,8.7,9.1,9.6)
y <- c(9.9,9.0,11.1,9.6,8.7,10.4)
nc <- 0.95
ns <- 1-nc
aux <- t.test(x,y,alternative = "two.sided", conf.level = nc, var.equal = T)
verificaHO(aux$p.value,ns)
verificaNormalidade(x,ns)
verificaNormalidade(y,ns)
var.test(x,y)
verificaVariancias(x,y,ns)
voca <- t.test(vinte_anos,sessenta_anos,alternative = "two.sided", conf.level = nc, var.equal = T)
verificaHO(voca$p.value)
verificaNormalidade(vinte_anos)
verificaNormalidade(sessenta_anos)
verificaVariancias(vinte_anos, sessenta_anos)
load("response.time.RData")
View(response.time)
dados < response.time[response.time$slave_count == 1]
dados <- response.time[response.time$slave_count == 1]
dados <- response.time[response.time$slave_count == 1,]
View(dados)
farthest <- dados[dados$slave_info == 'farthest']
farthest <- dados[dados$slave_info == 'farthest',]
farthest <- dados[dados$slave_info == 'farthest',]
farthest
View(farthest)
nearest <- dados[dados$slave_info == 'nearest',]
verificaNormalidade(farthest)
verificaNormalidade(nearest)
verificaNormalidade(nearest$value)
verificaNormalidade(farthest$value)
aux <- wilcox.test(x = nearest,y = farthest)
aux <- wilcox.test(x = nearest$value,y = farthest$value)
aux$p.value
verificaHO(aux$p.value)
aux <- wilcox.test(x = farthest$value,y = nearest$value)
verificaHO(aux$p.value)
aux
verificaHO(aux$p.value)
aux <- wilcox.test(x = nearest$value,y = farthest$value)
aux
verificaHO(aux$p.value)
pnorm(30,mean = 50, 10)
pnorm(500,mean = 400, 45)
1-pnorm(30,mean = 50, 10)
pnorm(30,mean = 50, 10)
pnorm(30,mean = 50, 10)
1-(pnorm(500,mean = 400, 45))*100
################################################################################
(pnorm(500,mean = 400, 45))*100
################################################################################
(pnorm(500,mean = 400, 45))*100
(1-pnorm(500, mean= 400, sd= 45))*100
(1-pnorm(500, mean= 400, sd= 45))*100
################################################################################
(1-pnorm(500,mean = 400, 45))*100
################################################################################
(1-pnorm(500,mean = 400, 45))*100
(1-pnorm(500,mean = 400, 45))*100
pnorm(500,mean = 400, 45))*100
################################################################################
(1-pnorm(500,mean = 400, 45))*100
################################################################################
(pnorm(500,mean = 400, 45))*100
################################################################################
(1-pnorm(500,mean = 400, 45))*100
################################################################################
(1-pnorm(500,mean = 400, 45))
################################################################################
(1-pnorm(500,mean = 400, 45))*100
(1-pnorm(30, mean= 50, sd= 10))*100
(1-pnorm(500, mean= 400, sd= 45))*100
#################################################################################
load("bdims.RData")
View(bdims)
mulher <- bdims[bdims$sex == 0, ]
View(mulher)
amostra <- mulher$hgt
#Desviopadrão
d <-sd(amostra)
#Médiada amostra
x <-mean(amostra)
#Tamanhoda amostra
n <-length(amostra)
#Erro
error <-d/sqrt(n)
#Nível de confiança
nc<-(1-0.90)/2
#Limiteinferior
left <-x-(qt(nc,df=n-1, lower.tail= F)*error)
#Limitesuperior
right <-x+(qt(nc,df=n-1,lower.tail = F)*error)
cat("[",left, "-", right,"]")
#Desviopadrão
d <-sd(mean(amostra))
#Médiada amostra
x <-mean(amostra)
#Tamanhoda amostra
n <-length(amostra)
#Erro
error <-d/sqrt(n)
#Nível de confiança
nc<-(1-0.90)/2
#Limiteinferior
left <-x-(qt(nc,df=n-1, lower.tail= F)*error)
#Limitesuperior
right <-x+(qt(nc,df=n-1,lower.tail = F)*error)
cat("[",left, "-", right,"]")
#Desviopadrão
d <-sd(amostra)
#Médiada amostra
x <-mean(amostra)
#Tamanhoda amostra
n <-length(amostra)
#Erro
error <-d/sqrt(n)
#Nível de confiança
nc<-(1-0.985)/2
#Limiteinferior
left <-x-(qt(nc,df=n-1, lower.tail= F)*error)
#Limitesuperior
right <-x+(qt(nc,df=n-1,lower.tail = F)*error)
cat("[",left, "-", right,"]")
0.985*100
amostra <- mean(mulher$hgt)
amostra <- mulher$hgt
#Desviopadrão
d <-sd(amostra)
#Médiada amostra
x <-mean(amostra)
#Tamanhoda amostra
n <-length(amostra)
#Erro
error <-d/sqrt(n)
#Nível de confiança
nc<-(1-0.985)/2
#Limiteinferior
left <-x-(qt(nc,df=n-1, lower.tail= F)*error)
#Limitesuperior
right <-x+(qt(nc,df=n-1,lower.tail = F)*error)
cat("[",left, "-", right,"]")
Instrutor<-c(rep("Dr. Katz Professional Therapist",12),rep('Laura the Receptionist',12),rep('Ben Katz',12))                                                              Software <- c(rep(c(rep("A",4), rep("B",4), rep("C",4)),3))                  Words.per.minute<-c(35, 50, 55, 60, 65, 60, 70, 55, 45, 55, 60, 45, 55, 60, 75, 65, 60, 70, 75, 70, 65, 72, 73, 65, 55, 55, 70, 55, 65, 60, 70, 60, 60,62,63,65)
Instrutor<-c(rep("Dr. Katz Professional Therapist",12),rep('Laura the Receptionist',12),rep('Ben Katz',12))
Software <- c(rep(c(rep("A",4), rep("B",4), rep("C",4)),3))
Words.per.minute<-c(35, 50, 55, 60, 65, 60, 70, 55, 45, 55, 60, 45, 55, 60, 75, 65, 60, 70, 75, 70, 65, 72, 73, 65, 55, 55, 70, 55, 65, 60, 70, 60, 60,62,63,65)
ToothGrowth
######################################################################
aux <- data.frame(
Instrutor<-c(rep("Dr. Katz Professional Therapist",12),rep('Laura the Receptionist',12),rep('Ben Katz',12))
Software <- c(rep(c(rep("A",4), rep("B",4), rep("C",4)),3))
Words.per.minute<-c(35, 50, 55, 60, 65, 60, 70, 55, 45, 55, 60, 45, 55, 60, 75, 65, 60, 70, 75, 70, 65, 72, 73, 65, 55, 55, 70, 55, 65, 60, 70, 60, 60,62,63,65))
######################################################################
aux <- data.frame(
Instrutor<-c(rep("Dr. Katz Professional Therapist",12),rep('Laura the Receptionist',12),rep('Ben Katz',12)),
Software <- c(rep(c(rep("A",4), rep("B",4), rep("C",4)),3)),
Words.per.minute<-c(35, 50, 55, 60, 65, 60, 70, 55, 45, 55, 60, 45, 55, 60, 75, 65, 60, 70, 75, 70, 65, 72, 73, 65, 55, 55, 70, 55, 65, 60, 70, 60, 60,62,63,65))
View(aux)
######################################################################
aux <- data.frame(Instrutor, Software, Words.per.minute)
View(aux)
res.aov2 <- aov(Software ~ Words.per.minute + Instrutor, data = aux)
aux$Instrutor <- as.factor(aux$Instrutor)
res.aov2 <- aov(Software ~ Words.per.minute + Instrutor, data = aux)
res.aov2 <- aov(aux$Software~aux$Words.per.minute + Instrutor, data = aux)
aux$Software <- as.factor(aux$Software)
aux$Words.per.minute <- as.factor(aux$Words.per.minute)
res.aov2 <- aov(aux$Software~aux$Words.per.minute + Instrutor, data = aux)
summary(res.aov2)
View(res.aov2)
summary(ToothGrowth)
str(ToothGrowth)
head(ToothGrowth)
Instrutor<-c(rep("Dr. Katz Professional Therapist",12),rep('Laura the Receptionist',12),rep('Ben Katz',12))
Software <- c(rep(c(rep("A",4), rep("B",4), rep("C",4)),3))
Words.per.minute<-c(35, 50, 55, 60, 65, 60, 70, 55, 45, 55, 60, 45, 55, 60, 75, 65, 60, 70, 75, 70, 65, 72, 73, 65, 55, 55, 70, 55, 65, 60, 70, 60, 60,62,63,65)
######################################################################
aux <- data.frame(Instrutor, Software, Words.per.minute)
aux$Instrutor <- as.factor(aux$Instrutor)
aux$Software <- as.factor(aux$Software)
ToothGrowth$dose <- factor(ToothGrowth$dose)
str(ToothGrowth)
str(aux)
res.aov2 <- aov(aux$Software~aux$Instrutor + Words.per.minute, data = aux)
View(res.aov2)
res.aov2 <- aov(aux$Words.per.minute~aux$Instrutor + aux$Software, data = aux)
View(res.aov2)
summary(res.aov2)
library(rstatix)
library(dplyr)
library(gplots)
library(car)
library(ggpubr)
library(vca)
library(ez)
library(PMCMRplus)
aux %>%
group_by(Instrutor, Software) %>%
shapiro_test(Words.per.minute)
0.00124>0.05
View(VADeaths)
regions <- c("50-54","55-59", "60-64","65-69","70-79")
colors <- c("yellow", "orange", "red","#CC0000","#660000")
barplot(VADeaths, main = "Death rates",
xlab = "Population",
ylab = "Deaths",
col = colors,
beside = T)
legend("topleft",pch= c(15,15,15), col = colors, legend = regions)
regions <- c("50-54","55-59", "60-64","65-69","70-79")
colors <- c("yellow", "orange", "red","#CC0000","#660000")
barplot(VADeaths, main = "Death rates",
xlab = "Population",
ylab = "Deaths",
col = colors,
beside = T)
legend("topleft",pch= c(15,15,15), col = colors, legend = regions)
x <- c(9,8,3)
pct <- round(x/sum(x)*100)
lbls <- paste(pct,"%",sep = "")
pie(x, lbls,
main = "Pacientes",
col = rainbow(3))
legend("topright",
legend = c('moderado','leve','severo'),
cex = 0.8, fill = rainbow(length(x)))
wordcloud(corpus, min.freq = 3,max.words = 100,random.order = F,
rot.per = 0.35, colors = brewer.pal(8,"Dark2"),scale = c(8,.4))
library(twitteR)
library(tm)
library(wordcloud)
consumer_key <- 'UHofBVArdC2gfi8somGlqLpEJ'
consumer_secret <- 'jeGKAiSfkWP5uejxR2elF12qYtKoU5RdCDjMdcUE3vFLDw7R02'
access_token <- '701928852105392130-CEzsgpEPL4HUEr6Xn69sFbwHvLG0CCS'
access_secret <- 'eZXiGLQ4sC1KpgNSa0dB1Oy9ZZeskgvIqgjEg3oCxuZsH'
setup_twitter_oauth(consumer_key, consumer_secret,
access_token, access_secret)
#consultando o twitter
tweets <- searchTwitter("#COVID19",n = 500, lang = 'pt')
#convertendo os twittes para o formato de DF
tweets <- twListToDF(tweets)
#colapsando todos os twittes em um vetor de uma posição
tweets_t <- paste(tweets$text, collapse = " ")
#Criando o source e corpus
tweets_t <- VectorSource(tweets_t)
corpus <- Corpus(tweets_t)
#limpeza
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("portuguese"))
inspect(corpus)
#remover URL's
removeURL <- function(x) gsub("http[^[:space:]]*","",x)
corpus <- tm_map(corpus,removeURL)
#remove qualquer coisa que n seja letras em português e espaço
removeNUmPunct <- function(x) gsub("[^[:alpha:][:space:]]*", "", x)
corpus <- tm_map(corpus,content_transformer(removeNUmPunct))
#criar matriz
dtm <- TermDocumentMatrix(corpus)
dtm <- as.matrix(dtm)
#fornecer a frequencia de cada palavra
fre <- sort(rowSums(dtm), decreasing = TRUE)
wordcloud(corpus, min.freq = 3,max.words = 100,random.order = F,
rot.per = 0.35, colors = brewer.pal(8,"Dark2"),scale = c(8,.4))
